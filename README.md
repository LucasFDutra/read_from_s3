# üßê 1. OBJETIVO

Estudar mais a fundo uma maneira de utilizar uma aplica√ß√£o serverless constru√≠da em python, com o localstack e o serverless framework, sendo que essa aplica√ß√£o rodaria na aws.

A aplica√ß√£o em s√≠ √© uma fun√ß√£o lambda que ativa com um evento de inser√ß√£o de arquivo no em um bucket do s3, processa esse arquivo e devolve para o mesmo bucket em outra pasta, sendo que o arquivo em quest√£o √© um csv.

Ou seja, cai um csv em uma dada pasta do bucket, a lambda √© ativada, abre o csv, processa e devolve o mesmo.

## 1.1 O CSV DE INPUT

O arquivo que usarei como teste se encontra [aqui]('./read_from_s3/read_from_s3/test/utils/files/class.csv') e a tabela abaixo mostra como ele deve ser;

|NAME|POINTS|
|-|-|
|a|10|
|b|8|
|c|7|

## 1.2 O CSV DE INPUT

O novo csv ser√° id√™ntico ao de input, com a adi√ß√£o de uma linha, sendo que essa linha √© a m√©dia dentre os valores das demais.

|NAME|POINTS|
|-|-|
|a|10|
|b|8|
|c|7|
|MEAN|8.333333333333334|

Esse valor ser√° calculado pela biblioteca do Pandas. N√£o existe real motivo em utilizar essa lib considerando um conjunto de dados t√£o pequeno, n√£o teria perda nenhuma de performance caso utilizasse a lib 'csv' j√° existente no python, assim evitando pesar a sua fun√ß√£o lambda. Mas o meu objetivo aqui era justamente fazer um teste com utiliza√ß√£o de depend√™ncias, pois assim eu conseguiria saber exatamente o que fazer quando precisar.

## 1.3 ESQUEMA DE FUNCIONAMENTO
<h1 align="center">
    <img src = './img/fig_01.png'/>
</h1>

# üìë 2. COMO USAR

## 2.1 INSTALA√á√ïES

### 2.1.1 PYTHON E AFINS
- Python: Para instalar o python v√° at√© a [python.org](https://www.python.org/) e siga as instru√ß√µes, mas se for usu√°rio linux o python j√° est√° instalado.

- Poetry: O [poetry](https://python-poetry.org/) √© um gerenciador de pacotes do python, que ajuda bastante, mas √© opcional. Para instal√°-lo:
    ```sh
    $ pip install --user poetry
    ```

- Venv: Recomendo utilizar um ambiente virtual, mas √© opcional
    ```sh
    $ sudo apt-get install python3-venv
    ```

- Pandas: √â bom instalar o pandas na sua m√°quina local pois assim voc√™ poder√° rodar os testes.
    - se tiver o poetry:
    ```sh
    $ poetry install
    ```
    - se n√£o:
    ```sh
    $ pip install pandas
    $ pip install boto3
    $ pip install pytest
    $ pip install pytest-cov
    ```

### 2.1.2 DOCKER

Para rodar o localstack voc√™ vai precisar do docker instalado, se voc√™ utiliza windows ou mac, ent√£o veja os passos na documenta√ß√£o [aqui](https://docs.docker.com/get-docker/). Mas se utiliza linux, ent√£o rode os comandos abaixo (se n√£o utiliza o apt como instalador, ent√£o troque para o seu onde chamo o apt).

```sh
$ sudo apt install docker.io
$ sudo curl -L "https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
$ sudo chmod +x /usr/local/bin/docker-compose
$ sudo groupadd docker
$ sudo usermod -aG docker $USER
$ su $USER
```

### 2.1.3 SERVERLESS FRAMWORK

Voc√™ pode olhar na documenta√ß√£o do mesmo [aqui](https://www.serverless.com/framework/docs/getting-started/) pois tem como instalar via curl, mas eu escolhi instalar via npm, e pra isso precisaremos de instalar o node, e pra isso basta ir na p√°gina do node e seguir a instala√ß√£o [aqui](https://nodejs.org/en/).

Ent√£o depois voc√™ pode digitar no terminal:

```sh
$ npm install -g serverless
```

E agora instale o plugin do serverless-localstack para que o framework aponte para dentro do container do localstack

```sh
$ serverless plugin install --name serverless-localstack
```

### 2.1.4 AWS CLI

Caso queira subir o projeto para a aws, voc√™ deve instalar a cli da aws, o que √© bem simples, basta entrar [aqui](https://aws.amazon.com/cli/) escolher seu sistema e seguir as instru√ß√µes. Depois configure a cli com o comando `$ aws configure` e pronto. Mas se n√£o quiser subir o projeto e manter ele somente no localstack, ent√£o n√£o precisa instalar.

### ‚ö†Ô∏è IMPORTANTE

Caso queira subir para a aws ent√£o troque o nome do bucket no arquivo `read_from_s3/src/serverless.yml` na linha 5, pois a aws n√£o permite dois buckets com o mesmo nome, e esse eu j√° criei.

```yaml
custom:
  bucketName: muly-dev
```

E tamb√©m, troque o bucket dentro do arquivo `read_from_s3/test/utils/files/event.json` nas linhas 23 e 27.

```json
"bucket": {
    "name": "muly-dev",
    "ownerIdentity": {
    "principalId": "EXAMPLE"
    },
    "arn": "arn:aws:s3:::muly-dev"
},
```

## 2.2 COMO RODAR

### 2.2.1 LOCAL

Com tudo isso instalado voc√™ pode agora rodar os comando na seguinte ordem (sendo que seu terminal deve estar para dentro da pasta raiz do projeto, ou seja, no mesmo nivel que o docker-compose.yml):

- Se tiver o poetry

```sh
$ docker-compose up
$ poetry run sls_deploy
$ pytest
```

- Se n√£o tiver:
```sh
$ docker-compose up
$ python scripts.py
$ pytest
```

A lib pytest faz com que todos os nossos testes rodem, e em um dos testes um arquivo √© enviado para o bucket que est√° dentro do localstack. Ent√£o os testes est√£o cobrindo as unidades de c√≥digos (unit tests) e todo o processo (integration).

### 2.2.2 NA AWS

Para mandar para a aws esse projeto, voc√™ tem que ter configurado a cli seguindo os passos da documenta√ß√£o da mesma (inclusive criando o usu√°rio em IAM). Feito isso, voc√™ vai precisar somente de comentar a linha com o plugin do localstack que o serverless utiliza para apontar para o container. Para isso v√° no arquivo `read_from_s3/src/serverless.yml` e comente as linhas 28 e 29. E ent√£o rode o comando:

```sh
$ poetry run sls_deploy
# ou se n√£o tiver o poetry
$ python scripts.py
```

# ü§ø 3. INDO MAIS A FUNDO

Se quiser entender melhor a estrutura de pastas, o como o arquivo serverless.yml funciona, o que √© o localstack, o porque do arquivo scritps.py, o processo de instala√ß√£o de depend√™ncias na lambda e como fiz os testes, ent√£o continue lendo. Mas se n√£o quiser saber disso e s√≥ queria por para rodar, ent√£o pode parar por aqui mesmo, e muito obrigado pela aten√ß√£o.

## 3.1 ESTRUTURA
Abaixo a gente consegue ver a estrutura de pastas que montei.

```sh
.
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ poetry.lock
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ read_from_s3
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ src
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handler.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ serverless.yml
‚îÇ   ‚îî‚îÄ‚îÄ test
‚îÇ       ‚îú‚îÄ‚îÄ integration
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ localstack_test.py
‚îÇ       ‚îú‚îÄ‚îÄ unit
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ handler_test.py
‚îÇ       ‚îî‚îÄ‚îÄ utils
‚îÇ           ‚îú‚îÄ‚îÄ files
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ class.csv
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ event.json
‚îÇ           ‚îî‚îÄ‚îÄ mock
‚îÇ               ‚îî‚îÄ‚îÄ Client.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ scripts.py
‚îî‚îÄ‚îÄ view_logs.py
```

A minha ideia com essa estrutura foi primeiramente separar os arquivos de configura√ß√£o do projeto, por isso que os arquivos de `requirements.txt`, `scripts.py`, `view_logs.py`, `docker-compose.ym`l, `poetry.lock` e `pyproject.toml` est√£o na raiz e o projeto em si est√° dentro de `read_from_s3`. Esse estilo de repetir o nome do projeto em uma pasta interna √© algo bem comum na comunidade python, e achei legal de organizar assim. 


O segundo objetivo era separar tudo que era de testes do que era c√≥digo. Por isso das pastas `src` e `test`, mas como o python precisa que algo seja um pacote para ser import√°vel em outro arquivo eu preciso criar o arquivo `__init__.py` dentro da pasta `read_from_s3`, assim eu consigo importar o arquivo `handler.py` (que √© a fun√ß√£o serverless propriamente dita) dentro dos arquivos de teste.


Agora indo para dentro da pasta `src`, eu tenho a fun√ß√£o serverless e o arquivo `serverless.yml` juntos, assim as coisas que s√£o relativas a fun√ß√£o lambda ficam juntos, e quando crio essa fun√ß√£o na aws a minha raiz vai mostrar somente o `handler.py` sem toda essa estrutura de pastas, assim fica mais organizado l√° na aws. Pois se eu colocasse o `serverless.yml` em outro lugar eu teria que referenciar todo o caminho at√© o `handler.py` e na aws ter√≠amos todo esse caminho constru√≠do tamb√©m.


J√° na pasta de `test`, eu preferi criar subpastas que me auxiliaram a n√£o deixar os arquivos todos soltos e desorganizados. Para isso eu criei a pasta `integration` para os testes de integra√ß√£o (que envia o arquivo para o localstack e verifica se todo o processo ocorreu normalmente), a pasta `unit` que tem os testes unit√°rios, que testem cada fun√ß√£o do arquivo `handler.py` de forma individual. E a pasta `utils` que ficariam os meus arquivos de testes e fun√ß√µes de mock (vou explicar isso na parte de testes).


Dentro de `files` eu deixei o `class.csv` que ser√° utilizado durante todos os testes, e tamb√©m o arquivo `event.json`, que tamb√©m √© utilizado durante os testes para verificar se a fun√ß√£o interpreta o evento corretamente. Esse arquivo √© identico ao que √© gerado durante um evento na aws, eu criei ele atrav√©s do SAM-CLI da aws, voc√™ pode ver [aqui](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html) como instal√°-lo e utilizar o mesmo, ele cumpre a mesma fun√ß√£o do serverless framework, mas eu preferi trabalhar com o serverless (achei mais simples, e mais bem documentado e com a comunidade maior, assim facilita as pesquisas por d√∫vidas). E de dentro do SAM eu utilizei o m√©todo [generate-event](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-local-generate-event.html) para criar esse arquivo de evento. 


> OBS.: Se quiser instalar o SAM eu recomendo fazer isso via pip e n√£o via homebrew como descreve na documenta√ß√£o, pois para mim n√£o deu certo, para isso veja [aqui](https://pypi.org/project/aws-sam-cli/) no pypi.


> OBS.: Eu n√£o sei se o serverless gera um evento tamb√©m, por isso utilizei o sam, se souber como fazer isso dentro do pr√≥prio serverless me fale em uma issue por favor, pois iria simplificar ao utilizar somente um framework.


## 3.2 SERVERLESS

O serverless framework √© uma ferramenta que nos auxilia a criar aplica√ß√µes serverless para m√∫ltiplos providers de cloud. Recomendo ir at√© o site deles [serverless.com](https://www.serverless.com/) e ver mais sobre o servi√ßo e dar uma olhada na documenta√ß√£o.

Mas basicamente, atrav√©s dele n√≥s podemos criar nossa infraestrutura atrav√©s de c√≥digo, com arquivos declarativos (.yaml), parametrizando qual o arquivo ser√° o arquivo de c√≥digo da nossa fun√ß√£o, quais as configura√ß√µes da fun√ß√£o, quais servi√ßos ela se ligar√°, as permiss√µes para a fun√ß√£o, o trigger dela, e consequentemente tamb√©m conseguimos criar esses outros servi√ßos. E o pr√≥prio serverless possibilita e nos auxilia a efetuar testes localmente nas fun√ß√µes, e tamb√©m possui diversos plugins que podem ajudar mais ainda, um deles √© o pr√≥prio serverless-localstack que utilizamos para enviar a fun√ß√£o para dentro do container ao em vez de mand√°-la para a cloud.

### 3.2.1 O ARQUIVO SERVERLESS.YML

Toda a estrutura √© descrita dentro do arquivo serverless.yml, que est√° [aqui]('./read_from_s3/src/serverless.yml'). No meu caso eu queria descrever uma fun√ß√£o lambda que ativaria assim que um arquivo fosse criado dentro de um bucket chamado 'muly-dev', mais especificamente dentro da pasta 'uploads', processasse isso e devolvesse o arquivo para dentro do mesmo bucket, mas dentro da pasta 'output'. Para isso eu precisaria descrever no meu arquivo o bucket, a fun√ß√£o e seu evento de ativa√ß√£o, e as permiss√µes para essa fun√ß√£o. Nisso o arquivo ficou da seguinte forma:

```yml
service: read-from-s3
frameworkVersion: '2'

custom:
  bucketName: muly-dev

provider:
  name: aws
  runtime: python3.8
  region: us-east-1
  iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:GetObject
        - s3:PutObject
      Resource: 'arn:aws:s3:::${self:custom.bucketName}/*'

functions:
  reads3:
    handler: handler.lambda_handler
    events:
      - s3:
          bucket: ${self:custom.bucketName}
          event: s3:ObjectCreated:*
          rules:
            - prefix: uploads/

plugins:
  - serverless-localstack
```

Agora vamos isolar cada parte dele e explicar uma por uma:

---
#### Configura√ß√µes gerais

```yml
service: read-from-s3
frameworkVersion: '2'
```

Nessa primeira parte, eu configurei o nome do servi√ßo, ou seja, o nome da fun√ß√£o lambda l√° na aws, e qual vers√£o do serverless que eu irei utilizar para poder trabalhar.

---
#### Vari√°veis do pr√≥prio arquivo

```yml
custom:
  bucketName: muly-dev
```

Eu utilizo essa parte de custom para definir algumas vari√°veis do pr√≥prio arquivo, ou seja, eu atribuo para dentro da vari√°vel `bucketName` o nome do meu bucket, e em todos os lugares do arquivo em que eu precisar citar esse bucket eu chamo a vari√°vel, evitando repetir o nome do bucket em v√°rios locais e facilitando troca de nome de bucket futuramente.

---

#### Configura√ß√µes gerais da fun√ß√£o

```yml
provider:
  name: aws
  runtime: python3.8
  region: us-east-1
  iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:GetObject
        - s3:PutObject
      Resource: 'arn:aws:s3:::${self:custom.bucketName}/*'
```

Nessa parte eu coloco o provider, ou seja, aws, google, azure. A regi√£o do provider em que minha fun√ß√£o ficar√°, nesse caso us-east-1 (Virginia), e estabele√ßo as permiss√µes da minha fun√ß√£o, que nesse caso ela pode pegar e colocar arquivos no bucket que √© referenciado pela vari√°vel bucketName.

Nessa parte tamb√©m √© onde eu colocaria o tamanho de mem√≥ria que a fun√ß√£o ocuparia, bem como o timeout dela, mas eu n√£o coloquei isso e deixei o default.

---

#### Configura√ß√µes de c√≥digo

```yml
functions:
  reads3:
    handler: handler.lambda_handler
    events:
      - s3:
          bucket: ${self:custom.bucketName}
          event: s3:ObjectCreated:*
          rules:
            - prefix: uploads/
```

Nessa parte eu defino a fun√ß√£o propriamente dita, dando para ela um nome (reads3) que √© referenciado somente dentro desse arquivo, esse n√£o √© o nome dela no provider, esse nome foi definido em service l√° no inicio. Mas eu aponto qual a fun√ß√£o handler dessa lambda, ou seja, a fun√ß√£o a ser executada assim que o evento for disparado. e nesse cado √© uma fun√ß√£o que est√° dentro do arquivo handler e essa fun√ß√£o √© a fun√ß√£o lambda_handler.

E tamb√©m defini qual o evento que ir√° disparar essa lambda, que no caso defini como sendo um evento do s3, no bucket referente a vari√°vel bucketName quando ocorrer a cria√ß√£o de um objeto dentro da pasta uploads.

---
#### Plugins

```yml
plugins:
  - serverless-localstack
```

Essa parte √© criada automaticamente quando instalamos algum plugin, e ele mesmo se coloca na lista de plugins, mas se voc√™ instalar algum e ele n√£o aparecer aqui ent√£o adicione-o aqui.

## 3.3 LOCALSTACK

O localstack √© uma ferramenta que simula um ambiente da aws na sua m√°quina atrav√©s de um container docker. Ele tem um modo free e o modo pro, a diferen√ßa entre eles est√° na quantidade de servi√ßos que conseguimos simular. [Aqui](https://github.com/localstack/localstack) est√° o github do projeto, que √© mais bem documentado do que o site deles, de uma olhada no projeto, e leia o readme deles para ver as configura√ß√µes que consegue fazer e os servi√ßos que consegue simular.

## 3.4 `SCRIPTS.PY`

Esse arquivo √© utilizado para rodar algumas coisas automaticamente para mim. E atrav√©s do poetry eu consigo adicionar ele na minha lista de comandos colocando dentro do arquivo `pyproject.toml` uma linha indicando o arquivo e qual fun√ß√£o dele ir√° executar mediante um comando.

```Python
[tool.poetry.scripts]
sls_deploy = "scripts:sls_deploy"
```

Com isso eu indico que quando rodar o comando `poetry run sls_deploy` na verdade eu vou estar mandando o python executar a fun√ß√£o `sls_deploy` l√° dentro do arquivo `scripts.py`. Essa fun√ß√£o pode ser vista abaixo:


```Python
import os

def sls_deploy():
    path_code_from = os.path.join('read_from_s3', 'src')
    path_code_to = os.path.join('.', 'src_tmp')
    os.system('cp -r '+path_code_from+' '+path_code_to)
    os.system('pip install -r requirements.txt -t '+path_code_to)
    os.system('cd '+ path_code_to +' && sls deploy')
    os.system('rm -r '+ path_code_to)

if __name__ == "__main__":
    sls_deploy()
```

a fun√ß√£o sls_deploy faz uma serie de comandos no terminal, primeiro ela:
- copia a pasta `read_from_s3/src` para a raiz em uma pasta chamada `src_tmp`;
- Instala dentro dessa pasta os pacotes listados no `requirements.txt`
- Entra nessa pasta e envia para dentro do localstack ou a aws todo o conte√∫do da pasta
- E depois de enviar tudo a pasta √© apagada

> A parte do `if __name__` √© para possibilitar que o arquivo seja executado atrav√©s do comando python scripts.py para quem n√£o tem o poetry.

Eu preferi fazer esse processo de copiar a pasta, instalar as depend√™ncias dentro da c√≥pia e mandar tudo isso e depois apagar a copia com as depend√™ncias, pois assim eu n√£o fico com o c√≥digo principal todo polu√≠do cheio de libs dentro dele. O processo fica mais lento dessa forma, mas eu preferi fazer assim para n√£o deixar bagun√ßado e confuso com esse tanto de pacotes que s√£o instalados (recomendo comentar a linha que apaga tudo e ver o tanto de coisa que fica ali).

### 3.4.1 `REQUIREMENTS.TXT`

Esse arquivo cont√©m as libs que ser√£o necess√°rias de instalar no pacote serverless, facilitando a vida, pois assim eu consigo instalar o que √© necess√°rio com um comando apenas.

## 3.5 TESTES

### 3.5.1 MOCK

Quando estamos mocando algo, estamos escondendo algo. E no caso de um teste, estamos escondendo alguma fun√ß√£o, chamada a apis, objetos...

Fazemos isso porque essas partes de c√≥digos nos j√° sabemos que elas funcionam corretamente e adicion√°-las ao nosso teste acaba gerando lentid√£o. E tamb√©m porque essa parte em espec√≠fico n√£o faz parte do teste que queremos executar. Pense no exemplo a seguir:

- Voc√™ tem uma fun√ß√£o que faz uma requeste a uma api de terceiros, se voc√™ deixar a sua fun√ß√£o ir at√© essa api ent√£o voc√™s n√£o vai estar testando somente sua fun√ß√£o, mas tamb√©m a api. Ent√£o al√©m de testar coisas que voc√™ n√£o quer, a resposta da api vai demorar e deixar o teste lento. Ent√£o uma forma interessante de fazer isso √© for√ßar o sua fun√ß√£o a buscar um arquivo que tem a exata mesma estrutura do retorno da api. Mas para fazer isso voc√™ precisa fazer inje√ß√£o de depend√™ncias. Para entender isso vamos para um exemplo, que √© o meu caso aqui. Eu preciso inst√¢nciar um cliente da sdk da aws para que esse cliente busque e envie arquivos para o meu bucket. Agora imagine se na minha fun√ß√£o respons√°vel por inserir o arquivo eu fizesse o seguinte:

```Python
def save_in_s3(data, bucket):
    client = boto3.client('s3')
    client.send_file(data, bucket)
    return True
```

> OBS.: Esse m√©todo send_file n√£o existe, eu s√≥ coloquei isso para ficar mais simples.

Nesse caso eu poderia testar minha aplica√ß√£o, mas √© inevit√°vel que o client inst√¢nciado seja o cliente real da aws, e isso vai fazer com que no momento em que eu rode o teste o arquivo v√° realmente parar dentro da aws. E eu n√£o quero isso. Logo eu preciso encontrar uma forma de evitar isso. E essa forma √© injetando o client dentro da fun√ß√£o, ou seja:

```Python
def save_in_s3(data, bucket, client):
    client.send_file(data, bucket)
    return True
```

Pronto, agora eu passo o client como par√¢metro para a fun√ß√£o, e nisso eu posso criar uma classe client fake, que tenha o m√©todo send_file, que recebe os par√¢metros da mesma forma que o client original, mas que nesse caso n√£o faz nada com o dado (se eu estivesse buscando algo, ent√£o eu apontaria um arquivo, que foi o que fiz no outro caso).

Assim o arquivo de mock fica da seguinte forma:

```Python
class Client():
    def put_object(self, Body, Bucket, Key, ContentType):
        return True

    def get_object(self, Bucket, Key):
        return {
            'Body': Key
        }
```

E dentro do meu teste eu passo:

```Python
from read_from_s3.src import handler
from read_from_s3.test.utils.mock import Client
import pandas as pd

mean_value = (10 + 8 + 7)/3
test_csv_file_path = os.path.join('read_from_s3', 'test', 'utils', 'files', 'class.csv')

def test_save_in_s3():
    client = Client.Client()
    data = pd.DataFrame({'NAME': {0: 'a', 1: 'b', 2: 'c', 3: 'MEAN'}, 'POINTS': {0: 10, 1: 8, 2: 7, 3: mean_value}})
    assert handler.save_in_s3(data, client, 'muly-dev') == True

def test_read_csv():
    data = handler.read_csv(test_csv_file_path).to_dict()
    correct_res = {'NAME': {0: 'a', 1: 'b', 2: 'c'}, 'POINTS': {0: 10, 1: 8, 2: 7}}
    assert data == correct_res
```

Veja que quando eu rodo o teste as fun√ß√µes recebem o client instanciado a partir do meu mock, que em um caso n√£o faz nada e no outro aponta para um arquivo do meu pc (Key, que √© o csv dentro de files)

### 3.5.2 UNIT

Para os testes de unidade, eu vou mostrar a fun√ß√£o em s√≠ e o c√≥digo dela.

#### get_client

- Fun√ß√£o: Essa fun√ß√£o seleciona as configura√ß√µes que o client deve ter de acordo com o ambiente. Se a vari√°vel de ambiente LOCALSTACK_HOSTNAME existir, ent√£o quer dizer que estou dentro do localstack e n√£o quero me conectar com a aws de verdade.

```Python
def get_client():
    if ('LOCALSTACK_HOSTNAME' in os.environ):
        client_config = {
            'service_name': 's3',
            'aws_access_key_id': '123',
            'aws_secret_access_key': '123',
            'endpoint_url': 'http://'+os.environ['LOCALSTACK_HOSTNAME']+':4566'
        }
    else:
        client_config = {
            'service_name': 's3'
        }
    return client_config
```

- Testes:
    - Teste 1: Cria a vari√°vel de ambiente LOCALSTACK_HOSTNAME e espera que as configura√ß√µes que retornarem sejam as referentes ao localstack.

```Python
def test_get_client_local():
    os.environ['LOCALSTACK_HOSTNAME'] = 'localhost'
    correct_res = {
        'service_name': 's3',
        'aws_access_key_id': '123',
        'aws_secret_access_key': '123',
        'endpoint_url': 'http://localhost:4566'
    }
    res = handler.get_client()
    assert res == correct_res
```

    - Teste 2: Apaga a vari√°vel de ambiente LOCALSTACK_HOSTNAME, para garantir que ela n√£o exista no sistema, e espera que as configura√ß√µes que retornarem sejam as referentes a aws.

```Python
def test_get_client_cloud():
    del os.environ['LOCALSTACK_HOSTNAME']
    correct_res = {
        'service_name': 's3'
    }
    res = handler.get_client()
    assert res == correct_res
```

---

#### save_in_s3

- Fun√ß√£o: Pega os dados de um dataframe chamado `data` e converte isso para uma string gigante e depois utiliza o m√©todo put_object para adicionar o arquivo ao bucket e retorna True.

```Python
def save_in_s3(data, client, bucket):
    rows = [','.join(list(data.columns))]
    for row in data.values:
        rows.append(','.join(map(str, row)))
    rows = '\n'.join(rows)
    file_name = 'output/final_data.csv'
    client.put_object(Body=rows, Bucket=bucket, Key=file_name, ContentType='csv') 
    print('Arquivo '+ file_name +' subiu com sucesso')
    return True
```

- Teste: Passa para a fun√ß√£o o client mocado, e os dados criado pelo dicion√°rio e convertidos em dataframe pelo pandas, e ent√£o verifica se a fun√ß√£o retorna True, o que indica que ela terminou sem erros

```Python
def test_save_in_s3():
    client = Client.Client()
    data = pd.DataFrame({'NAME': {0: 'a', 1: 'b', 2: 'c', 3: 'MEAN'}, 'POINTS': {0: 10, 1: 8, 2: 7, 3: mean_value}})
    assert handler.save_in_s3(data, client, 'muly-dev') == True
```

---

#### add_mean_to_data_frame

- Fun√ß√£o: Recebe o dataframe e adiciona a linha com o valor da m√©dia.

```Python
def add_mean_to_data_frame(data, mean):
    new_line = pd.DataFrame([['MEAN', mean]], columns=['NAME', 'POINTS'])
    new_data = pd.concat([data, new_line]).reset_index(drop=True)
    return new_data
```

- Teste: Passa os dados do csv (dentro de files), converte a resposta para um dicion√°rio e compara com o que deveria ser

```Python
def test_add_mean_to_data_frame():
    test_data = pd.read_csv(test_csv_file_path)
    res = handler.add_mean_to_data_frame(test_data, mean_value).to_dict()
    correct_res = {'NAME': {0: 'a', 1: 'b', 2: 'c', 3: 'MEAN'}, 'POINTS': {0: 10, 1: 8, 2: 7, 3: mean_value}}
    assert res == correct_res
```

---

#### get_mean

- Fun√ß√£o: Recebe o dataframe e retorna a m√©dia dos pontos.

```Python
def get_mean(data):
    return data.POINTS.mean()
```

- Teste: Envia um csv (dentro de files) e compara a resposta de retorno com o que deveria ser

```Python
def test_get_mean():
    test_data = pd.read_csv(test_csv_file_path)
    assert handler.get_mean(test_data) == mean_value
```

---

#### read_csv

- Fun√ß√£o: Retorna o dataframe criado pelo pandas a partir do caminho do arquivo.

```Python
def read_csv(file_path):
    data = pd.read_csv(file_path)
    return data
```

- Teste: Envia o arquivo csv (dentro de files) e compara o retorno com um dicion√°rio.

```Python
def test_read_csv():
    data = handler.read_csv(test_csv_file_path).to_dict()
    correct_res = {'NAME': {0: 'a', 1: 'b', 2: 'c'}, 'POINTS': {0: 10, 1: 8, 2: 7}}
    assert data == correct_res
```

---

#### main

- Fun√ß√£o: A fun√ß√£o main, identifica o bucket, e a key por meio do event. A key √© o caminho dentro do bucket que o aquivo criado est√°. E por meio da fun√ß√£o get_object o client consegue buscar esse arquivo, o qual √© lido pelo pandas e transformado em dataframe dentro da fun√ß√£o `read_csv`, e depois calcula a m√©dia e insere no dataframe e ent√£o salva no s3 novamente. Veja que essa fun√ß√£o na verdade percorre toda a aplica√ß√£o, por isso eu n√£o sei bem se deveria ter colocado ela como teste unit√°rio, mas na d√∫vida deixei aqui.

```Python
def main(event, client):
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']
    obj = client.get_object(Bucket=bucket, Key=key)['Body']
    data = read_csv(obj)
    mean = get_mean(data)
    data = add_mean_to_data_frame(data, mean)
    return save_in_s3(data, client, bucket)
```

- Teste: Passa o client mockado, e o arquivo event.json presente em files. Assim quando a fun√ß√£o `main` utilizar a fun√ß√£o` get_object` na verdade ela receber√° o retorno com a Key (como mostrei no mock), e essa key por sua vez aponta para o arquivo class.csv dentro de files. Assim eu consigo fazer o pandas ler o arquivo de testes, e n√£o buscar um dentro da cloud. Ent√£o depois disso eu comparo se o retorno da fun√ß√£o foi igual a True, j√° que esse √© o retorno da fun√ß√£o `save_in_s3` que √© o que a main retorna.

```Python
def test_main():
    client = Client.Client()
    with open(test_event_file_path, 'r') as event_file:
        event = json.load(event_file)
    assert handler.main(event, client) == True
```

---

### 3.5.3 INTEGRATION

De testes de integra√ß√£o eu fiz somente um. Nesse teste a fun√ß√£o `test_localstack` utiliza a sdk da aws, com o endpoint configurado para o container, e envia um arquivo para o bucket muly-dev, e ent√£o tenta resgatar a resposta da lambda dentro de um loop, que roda at√© chegar algum arquivo na pasta de output ou at√© 50 segundos. Ent√£o o teste l√™ o arquivo que retornou e compara com o que deveria ser.

```Python
import boto3
import time
import pandas as pd
import os

test_csv_file_path = os.path.join('read_from_s3', 'test', 'utils', 'files', 'class.csv')
mean_value = (10 + 8 + 7)/3

def mount_csv(data):
    rows = [','.join(list(data.columns))]
    for row in data.values:
        rows.append(','.join(map(str, row)))
    rows = '\n'.join(rows)
    return rows

def test_localstack():
    config_s3 = {
        'service_name': 's3',
        'aws_access_key_id': '123',
        'aws_secret_access_key': '123',
        'endpoint_url': 'http://localhost:4566'
    }

    bucket = 'muly-dev'
    input_key = 'uploads/class.csv'
    output_key = 'output/final_data.csv'

    test_file = mount_csv(pd.read_csv(test_csv_file_path))
    client = boto3.client(**config_s3)
    client.put_object(Body=test_file, Bucket=bucket, Key=input_key, ContentType='csv')

    n_files = 0
    initial_time = time.time()
    while ((n_files == 0) and ((time.time() - initial_time) < 50)):
        objects_list = client.list_objects_v2(Bucket=bucket, Prefix='output')
        n_files = objects_list['KeyCount']

    obj = client.get_object(Bucket=bucket, Key=output_key)['Body']
    res = pd.read_csv(obj).to_dict()
    correct_res = {'NAME': {0: 'a', 1: 'b', 2: 'c', 3: 'MEAN'}, 'POINTS': {0: 10, 1: 8, 2: 7, 3: mean_value}}
    assert res == correct_res
```