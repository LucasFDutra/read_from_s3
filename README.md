# üßê 1. OBJETIVO

Estudar mais a fundo uma maneira de utilizar uma aplica√ß√£o serverless constru√≠da em python, com o localstack e o serverless framework, sendo que essa aplica√ß√£o rodaria na aws.

A aplica√ß√£o em s√≠ √© uma fun√ß√£o lambda que ativa com um evento de inser√ß√£o de arquivo no em um bucket do s3, processa esse arquivo e devolve para o mesmo bucket em outra pasta, sendo que o arquivo em quest√£o √© um csv.

Ou seja, cai um csv em uma dada pasta do bucket, a lambda √© ativada, abre o csv, processa e devolve o mesmo.

## 1.1 O CSV DE INPUT

O arquivo que usarei como teste se encontra [aqui]('./read_from_s3/read_from_s3/test/utils/files/class.csv') e a tabela abaixo mostra como ele deve ser;

|NAME|POINTS|
|-|-|
|a|10|
|b|8|
|c|7|

## 1.2 O CSV DE INPUT

O novo csv ser√° id√™ntico ao de input, com a adi√ß√£o de uma linha, sendo que essa linha √© a m√©dia dentre os valores das demais.

|NAME|POINTS|
|-|-|
|a|10|
|b|8|
|c|7|
|MEAN|8.333333333333334|

Esse valor ser√° calculado pela biblioteca do Pandas. N√£o existe real motivo em utilizar essa lib considerando um conjunto de dados t√£o pequeno, n√£o teria perda nenhuma de performance caso utilizasse a lib 'csv' j√° existente no python, assim evitando pesar a sua fun√ß√£o lambda. Mas o meu objetivo aqui era justamente fazer um teste com utiliza√ß√£o de depend√™ncias, pois assim eu conseguiria saber exatamente o que fazer quando precisar.

## 1.3 ESQUEMA DE FUNCIONAMENTO
<h1 align="center">
    <img src = './img/fig_01.png' width=700/>
</h1>

# üìë 2. COMO USAR

## 2.1 INSTALA√á√ïES

### 2.1.1 PYTHON E AFINS
- Python: Para instalar o python v√° at√© a [python.org](https://www.python.org/) e siga as instru√ß√µes, mas se for usu√°rio linux o python j√° est√° instalado.

- Poetry: O [poetry](https://python-poetry.org/) √© um gerenciador de pacotes do python, que ajuda bastante, mas √© opcional. Para instal√°-lo:
    ```sh
    $ pip install --user poetry
    ```

- Venv: Recomendo utilizar um ambiente virtual, mas √© opcional
    ```sh
    $ sudo apt-get install python3-venv
    ```

- Pandas: √â bom instalar o pandas na sua m√°quina local pois assim voc√™ poder√° rodar os testes.
    - se tiver o poetry:
    ```sh
    $ poetry install
    ```
    - se n√£o:
    ```sh
    $ pip install pandas
    $ pip install boto3
    $ pip install pytest
    $ pip install pytest-cov
    ```

### 2.1.2 DOCKER

Para rodar o localstack voc√™ vai precisar do docker instalado, se voc√™ utiliza windows ou mac, ent√£o veja os passos na documenta√ß√£o [aqui](https://docs.docker.com/get-docker/). Mas se utiliza linux, ent√£o rode os comandos abaixo (se n√£o utiliza o apt como instalador, ent√£o troque para o seu onde chamo o apt).

```sh
$ sudo apt install docker.io
$ sudo curl -L "https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
$ sudo chmod +x /usr/local/bin/docker-compose
$ sudo groupadd docker
$ sudo usermod -aG docker $USER
$ su $USER
```

### 2.1.3 SERVERLESS FRAMWORK

Voc√™ pode olhar na documenta√ß√£o do mesmo [aqui](https://www.serverless.com/framework/docs/getting-started/) pois tem como instalar via curl, mas eu escolhi instalar via npm, e pra isso precisaremos de instalar o node, e pra isso basta ir na p√°gina do node e seguir a instala√ß√£o [aqui](https://nodejs.org/en/).

Ent√£o depois voc√™ pode digitar no terminal:

```sh
$ npm install -g serverless
```

E agora instale o plugin do serverless-localstack para que o framework aponte para dentro do container do localstack

```sh
$ serverless plugin install --name serverless-localstack
```

### 2.1.4 AWS CLI

Caso queira subir o projeto para a aws, voc√™ deve instalar a cli da aws, o que √© bem simples, basta entrar [aqui](https://aws.amazon.com/cli/) escolher seu sistema e seguir as instru√ß√µes. Depois configure a cli com o comando `$ aws configure` e pronto. Mas se n√£o quiser subir o projeto e manter ele somente no localstack, ent√£o n√£o precisa instalar.

### ‚ö†Ô∏è IMPORTANTE

Caso queira subir para a aws ent√£o troque o nome do bucket no arquivo `read_from_s3/src/serverless.yml` na linha 5, pois a aws n√£o permite dois buckets com o mesmo nome, e esse eu j√° criei.

```yaml
custom:
  bucketName: muly-dev
```

E tamb√©m, troque o bucket dentro do arquivo `read_from_s3/test/utils/files/event.json` nas linhas 23 e 27.

```json
"bucket": {
    "name": "muly-dev",
    "ownerIdentity": {
    "principalId": "EXAMPLE"
    },
    "arn": "arn:aws:s3:::muly-dev"
},
```

## 2.2 COMO RODAR

### 2.2.1 LOCAL

Com tudo isso instalado voc√™ pode agora rodar os comando na seguinte ordem (sendo que seu terminal deve estar para dentro da pasta raiz do projeto, ou seja, no mesmo nivel que o docker-compose.yml):

- Se tiver o poetry

```sh
$ docker-compose up
$ poetry run sls_deploy
$ pytest
```

- Se n√£o tiver:
```sh
$ docker-compose up
$ python scripts.py
$ pytest
```

A lib pytest faz com que todos os nossos testes rodem, e em um dos testes um arquivo √© enviado para o bucket que est√° dentro do localstack. Ent√£o os testes est√£o cobrindo as unidades de c√≥digos (unit tests) e todo o processo (integration).

### 2.2.2 NA AWS

Para mandar para a aws esse projeto, voc√™ tem que ter configurado a cli seguindo os passos da documenta√ß√£o da mesma (inclusive criando o usu√°rio em IAM). Feito isso, voc√™ vai precisar somente de comentar a linha com o plugin do localstack que o serverless utiliza para apontar para o container. Para isso v√° no arquivo `read_from_s3/src/serverless.yml` e comente as linhas 28 e 29. E ent√£o rode o comando:

```sh
$ poetry run sls_deploy
# ou se n√£o tiver o poetry
$ python scripts.py
```

# ü§ø 3. INDO MAIS A FUNDO

Se quiser entender melhor a estrutura de pastas, o como o arquivo serverless.yml funciona, o que √© o localstack, o porque do arquivo scritps.py, o processo de instala√ß√£o de depend√™ncias na lambda e como fiz os testes, ent√£o continue lendo. Mas se n√£o quiser saber disso e s√≥ queria por para rodar, ent√£o pode parar por aqui mesmo, e muito obrigado pela aten√ß√£o.

## 3.1 ESTRUTURA
Abaixo a gente consegue ver a estrutura de pastas que montei.

```sh
.
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ poetry.lock
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ read_from_s3
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ src
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handler.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ serverless.yml
‚îÇ   ‚îî‚îÄ‚îÄ test
‚îÇ       ‚îú‚îÄ‚îÄ integration
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ localstack_test.py
‚îÇ       ‚îú‚îÄ‚îÄ unit
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ handler_test.py
‚îÇ       ‚îî‚îÄ‚îÄ utils
‚îÇ           ‚îú‚îÄ‚îÄ files
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ class.csv
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ event.json
‚îÇ           ‚îî‚îÄ‚îÄ mock
‚îÇ               ‚îî‚îÄ‚îÄ Client.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ scripts.py
‚îî‚îÄ‚îÄ view_logs.py
```

A minha ideia com essa estrutura foi primeiramente separar os arquivos de configura√ß√£o do projeto, por isso que os arquivos de `requirements.txt`, `scripts.py`, `view_logs.py`, `docker-compose.ym`l, `poetry.lock` e `pyproject.toml` est√£o na raiz e o projeto em si est√° dentro de `read_from_s3`. Esse estilo de repetir o nome do projeto em uma pasta interna √© algo bem comum na comunidade python, e achei legal de organizar assim. 


O segundo objetivo era separar tudo que era de testes do que era c√≥digo. Por isso das pastas `src` e `test`, mas como o python precisa que algo seja um pacote para ser import√°vel em outro arquivo eu preciso criar o arquivo `__init__.py` dentro da pasta `read_from_s3`, assim eu consigo importar o arquivo `handler.py` (que √© a fun√ß√£o serverless propriamente dita) dentro dos arquivos de teste.


Agora indo para dentro da pasta `src`, eu tenho a fun√ß√£o serverless e o arquivo `serverless.yml` juntos, assim as coisas que s√£o relativas a fun√ß√£o lambda ficam juntos, e quando crio essa fun√ß√£o na aws a minha raiz vai mostrar somente o `handler.py` sem toda essa estrutura de pastas, assim fica mais organizado l√° na aws. Pois se eu colocasse o `serverless.yml` em outro lugar eu teria que referenciar todo o caminho at√© o `handler.py` e na aws ter√≠amos todo esse caminho constru√≠do tamb√©m.


J√° na pasta de `test`, eu preferi criar subpastas que me auxiliaram a n√£o deixar os arquivos todos soltos e desorganizados. Para isso eu criei a pasta `integration` para os testes de integra√ß√£o (que envia o arquivo para o localstack e verifica se todo o processo ocorreu normalmente), a pasta `unit` que tem os testes unit√°rios, que testem cada fun√ß√£o do arquivo `handler.py` de forma individual. E a pasta `utils` que ficariam os meus arquivos de testes e fun√ß√µes de mock (vou explicar isso na parte de testes).


Dentro de `files` eu deixei o `class.csv` que ser√° utilizado durante todos os testes, e tamb√©m o arquivo `event.json`, que tamb√©m √© utilizado durante os testes para verificar se a fun√ß√£o interpreta o evento corretamente. Esse arquivo √© identico ao que √© gerado durante um evento na aws, eu criei ele atrav√©s do SAM-CLI da aws, voc√™ pode ver [aqui](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html) como instal√°-lo e utilizar o mesmo, ele cumpre a mesma fun√ß√£o do serverless framework, mas eu preferi trabalhar com o serverless (achei mais simples, e mais bem documentado e com a comunidade maior, assim facilita as pesquisas por d√∫vidas). E de dentro do SAM eu utilizei o m√©todo [generate-event](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-local-generate-event.html) para criar esse arquivo de evento. 


> OBS.: Se quiser instalar o SAM eu recomendo fazer isso via pip e n√£o via homebrew como descreve na documenta√ß√£o, pois para mim n√£o deu certo, para isso veja [aqui](https://pypi.org/project/aws-sam-cli/) no pypi.


> OBS.: Eu n√£o sei se o serverless gera um evento tamb√©m, por isso utilizei o sam, se souber como fazer isso dentro do pr√≥prio serverless me fale em uma issue por favor, pois iria simplificar ao utilizar somente um framework.


## 3.2 SERVERLESS

O serverless framework √© uma ferramenta que nos auxilia a criar aplica√ß√µes serverless para m√∫ltiplos providers de cloud. Recomendo ir at√© o site deles [serverless.com](https://www.serverless.com/) e ver mais sobre o servi√ßo e dar uma olhada na documenta√ß√£o.

Mas basicamente, atrav√©s dele n√≥s podemos criar nossa infraestrutura atrav√©s de c√≥digo, com arquivos declarativos (.yaml), parametrizando qual o arquivo ser√° o arquivo de c√≥digo da nossa fun√ß√£o, quais as configura√ß√µes da fun√ß√£o, quais servi√ßos ela se ligar√°, as permiss√µes para a fun√ß√£o, o trigger dela, e consequentemente tamb√©m conseguimos criar esses outros servi√ßos. E o pr√≥prio serverless possibilita e nos auxilia a efetuar testes localmente nas fun√ß√µes, e tamb√©m possui diversos plugins que podem ajudar mais ainda, um deles √© o pr√≥prio serverless-localstack que utilizamos para enviar a fun√ß√£o para dentro do container ao em vez de mand√°-la para a cloud.

### 3.2.1 O ARQUIVO SERVERLESS.YML

Toda a estrutura √© descrita dentro do arquivo serverless.yml, que est√° [aqui]('./read_from_s3/src/serverless.yml'). No meu caso eu queria descrever uma fun√ß√£o lambda que ativaria assim que um arquivo fosse criado dentro de um bucket chamado 'muly-dev', mais especificamente dentro da pasta 'uploads', processasse isso e devolvesse o arquivo para dentro do mesmo bucket, mas dentro da pasta 'output'. Para isso eu precisaria descrever no meu arquivo o bucket, a fun√ß√£o e seu evento de ativa√ß√£o, e as permiss√µes para essa fun√ß√£o. Nisso o arquivo ficou da seguinte forma:

```yml
service: read-from-s3
frameworkVersion: '2'

custom:
  bucketName: muly-dev

provider:
  name: aws
  runtime: python3.8
  region: us-east-1
  iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:GetObject
        - s3:PutObject
      Resource: 'arn:aws:s3:::${self:custom.bucketName}/*'

functions:
  reads3:
    handler: handler.lambda_handler
    events:
      - s3:
          bucket: ${self:custom.bucketName}
          event: s3:ObjectCreated:*
          rules:
            - prefix: uploads/

plugins:
  - serverless-localstack
```

Agora vamos isolar cada parte dele e explicar uma por uma:

---
#### Configura√ß√µes gerais

```yml
service: read-from-s3
frameworkVersion: '2'
```

Nessa primeira parte, eu configurei o nome do servi√ßo, ou seja, o nome da fun√ß√£o lambda l√° na aws, e qual vers√£o do serverless que eu irei utilizar para poder trabalhar.

---
#### Vari√°veis do pr√≥prio arquivo

```yml
custom:
  bucketName: muly-dev
```

Eu utilizo essa parte de custom para definir algumas vari√°veis do pr√≥prio arquivo, ou seja, eu atribuo para dentro da vari√°vel `bucketName` o nome do meu bucket, e em todos os lugares do arquivo em que eu precisar citar esse bucket eu chamo a vari√°vel, evitando repetir o nome do bucket em v√°rios locais e facilitando troca de nome de bucket futuramente.

---

#### Configura√ß√µes gerais da fun√ß√£o

```yml
provider:
  name: aws
  runtime: python3.8
  region: us-east-1
  iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:GetObject
        - s3:PutObject
      Resource: 'arn:aws:s3:::${self:custom.bucketName}/*'
```

Nessa parte eu coloco o provider, ou seja, aws, google, azure. A regi√£o do provider em que minha fun√ß√£o ficar√°, nesse caso us-east-1 (Virginia), e estabele√ßo as permiss√µes da minha fun√ß√£o, que nesse caso ela pode pegar e colocar arquivos no bucket que √© referenciado pela vari√°vel bucketName.

Nessa parte tamb√©m √© onde eu colocaria o tamanho de mem√≥ria que a fun√ß√£o ocuparia, bem como o timeout dela, mas eu n√£o coloquei isso e deixei o default.

---

#### Configura√ß√µes de c√≥digo

```yml
functions:
  reads3:
    handler: handler.lambda_handler
    events:
      - s3:
          bucket: ${self:custom.bucketName}
          event: s3:ObjectCreated:*
          rules:
            - prefix: uploads/
```

Nessa parte eu defino a fun√ß√£o propriamente dita, dando para ela um nome (reads3) que √© referenciado somente dentro desse arquivo, esse n√£o √© o nome dela no provider, esse nome foi definido em service l√° no inicio. Mas eu aponto qual a fun√ß√£o handler dessa lambda, ou seja, a fun√ß√£o a ser executada assim que o evento for disparado. e nesse cado √© uma fun√ß√£o que est√° dentro do arquivo handler e essa fun√ß√£o √© a fun√ß√£o lambda_handler.

E tamb√©m defini qual o evento que ir√° disparar essa lambda, que no caso defini como sendo um evento do s3, no bucket referente a vari√°vel bucketName quando ocorrer a cria√ß√£o de um objeto dentro da pasta uploads.

---
#### Plugins

```yml
plugins:
  - serverless-localstack
```

Essa parte √© criada automaticamente quando instalamos algum plugin, e ele mesmo se coloca na lista de plugins, mas se voc√™ instalar algum e ele n√£o aparecer aqui ent√£o adicione-o aqui.

## 3.3 LOCALSTACK

O localstack √© uma ferramenta que simula um ambiente da aws na sua m√°quina atrav√©s de um container docker. Ele tem um modo free e o modo pro, a diferen√ßa entre eles est√° na quantidade de servi√ßos que conseguimos simular. [Aqui](https://github.com/localstack/localstack) est√° o github do projeto, que √© mais bem documentado do que o site deles, de uma olhada no projeto, e leia o readme deles para ver as configura√ß√µes que consegue fazer e os servi√ßos que consegue simular.

## 3.4 `SCRIPTS.PY`

Esse arquivo √© utilizado para rodar algumas coisas automaticamente para mim. E atrav√©s do poetry eu consigo adicionar ele na minha lista de comandos colocando dentro do arquivo `pyproject.toml` uma linha indicando o arquivo e qual fun√ß√£o dele ir√° executar mediante um comando.

```Python
[tool.poetry.scripts]
sls_deploy = "scripts:sls_deploy"
```

Com isso eu indico que quando rodar o comando `poetry run sls_deploy` na verdade eu vou estar mandando o python executar a fun√ß√£o `sls_deploy` l√° dentro do arquivo `scripts.py`. Essa fun√ß√£o pode ser vista abaixo:


```Python
import os

def sls_deploy():
    path_code_from = os.path.join('read_from_s3', 'src')
    path_code_to = os.path.join('.', 'src_tmp')
    os.system('cp -r '+path_code_from+' '+path_code_to)
    os.system('pip install -r requirements.txt -t '+path_code_to)
    os.system('cd '+ path_code_to +' && sls deploy')
    os.system('rm -r '+ path_code_to)

if __name__ == "__main__":
    sls_deploy()
```

a fun√ß√£o sls_deploy faz uma serie de comandos no terminal, primeiro ela:
- copia a pasta `read_from_s3/src` para a raiz em uma pasta chamada `src_tmp`;
- Instala dentro dessa pasta os pacotes listados no `requirements.txt`
- Entra nessa pasta e envia para dentro do localstack ou a aws todo o conte√∫do da pasta
- E depois de enviar tudo a pasta √© apagada

> A parte do `if __name__` √© para possibilitar que o arquivo seja executado atrav√©s do comando python scripts.py para quem n√£o tem o poetry.

Eu preferi fazer esse processo de copiar a pasta, instalar as depend√™ncias dentro da c√≥pia e mandar tudo isso e depois apagar a copia com as depend√™ncias, pois assim eu n√£o fico com o c√≥digo principal todo polu√≠do cheio de libs dentro dele. O processo fica mais lento dessa forma, mas eu preferi fazer assim para n√£o deixar bagun√ßado e confuso com esse tanto de pacotes que s√£o instalados (recomendo comentar a linha que apaga tudo e ver o tanto de coisa que fica ali).

### 3.4.1 `REQUIREMENTS.TXT`

Esse arquivo cont√©m as libs que ser√£o necess√°rias de instalar no pacote serverless, facilitando a vida, pois assim eu consigo instalar o que √© necess√°rio com um comando apenas.

## 3.5 TESTES